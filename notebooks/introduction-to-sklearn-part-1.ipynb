{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3ea2c52-3ead-4484-8a13-59ff459b0f78",
   "metadata": {
    "id": "e3ea2c52-3ead-4484-8a13-59ff459b0f78"
   },
   "outputs": [],
   "source": [
    "import pathlib\n",
    "import requests\n",
    "\n",
    "import joblib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import linear_model, model_selection, metrics, utils\n",
    "from sklearn import pipeline, preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9b241c6-de2e-4c9a-ac4f-6c5a010e2929",
   "metadata": {
    "id": "a9b241c6-de2e-4c9a-ac4f-6c5a010e2929",
    "tags": []
   },
   "source": [
    "# Working with Real Data\n",
    "\n",
    "When you are just getting started with machine learning it is best to experiment with real-world data (as opposed to artificial data). The following are some good resources of open-source data that you can use for practice or research.\n",
    "\n",
    "* [University of California-Irvine Machine Learning Repository](http://archive.ics.uci.edu/ml/)\n",
    "* [Kaggle](https://www.kaggle.com/datasets),\n",
    "* [OpenDataMonitor](http://opendatamonitor.eu/),\n",
    "* [Wikipedia's list of Machine Learning datasets](https://en.wikipedia.org/wiki/List_of_datasets_for_machine-learning_research)\n",
    "* [Datasets subreddit](https://www.reddit.com/r/datasets/),\n",
    "* [Quora's list of open datasets](https://www.quora.com/Where-can-I-find-large-datasets-open-to-the-public)\n",
    "\n",
    "Major cloud providers all have repositories of publically available datasets.,\n",
    "\n",
    "* [Open Data on AWS](https://registry.opendata.aws/),\n",
    "* [Open Data on GCP](https://cloud.google.com/public-datasets/),\n",
    "* [Open Data on Azure](https://azure.microsoft.com/en-us/services/open-datasets/),\n",
    "    \n",
    "Finally, [Pandas DataReader](https://pydata.github.io/pandas-datareader/) provides a unified API to a [number of datasets](https://pydata.github.io/pandas-datareader/remote_data.html). Note that many of these data sources require you to create an account and get an API key.\n",
    "\n",
    "## MNIST Dataset\n",
    "\n",
    "The original [MNIST](http://yann.lecun.com/exdb/mnist/) dataset consists of 70000 28x28 black and white images in 10 classes. There are 60000 training images and 10000 test images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92587a9e-0b12-49cc-aa00-93c905c60278",
   "metadata": {},
   "outputs": [],
   "source": [
    "# might be different if using Colab or Kaggle\n",
    "PROJECT_ROOT_DIR = pathlib.Path(\"..\")\n",
    "\n",
    "DATA_DIR = PROJECT_ROOT_DIR / \"data\" / \"mnist\"\n",
    "DATA_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "RESULTS_DIR = PROJECT_ROOT_DIR / \"results\" / \"mnist\"\n",
    "RESULTS_DIR.mkdir(parents=True, exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e68d2238-7283-441a-b6d8-4ba3c4c682f0",
   "metadata": {
    "id": "e68d2238-7283-441a-b6d8-4ba3c4c682f0"
   },
   "source": [
    "### Download and extract the data (if using Colab or Kaggle!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09916110-f2d8-448c-86ee-4be9ae5be169",
   "metadata": {
    "id": "09916110-f2d8-448c-86ee-4be9ae5be169",
    "tags": []
   },
   "outputs": [],
   "source": [
    "URL = \"https://github.com/KAUST-Academy/practical-tools-for-machine-learning/blob/october-2022/data/mnist/mnist.parquet?raw=true\"\n",
    "\n",
    "with open(DATA_DIR / \"mnist.parquet\", 'wb') as f:\n",
    "    response = requests.get(URL)\n",
    "    f.write(response.content)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02cc24c9-260e-4840-8872-723f0adc6f41",
   "metadata": {
    "id": "02cc24c9-260e-4840-8872-723f0adc6f41"
   },
   "source": [
    "### Load the data\n",
    "\n",
    "We will load the data using the [Pandas](https://pandas.pydata.org/) library. Highly recommend the most recent edition of [*Python for Data Analysis*](https://learning.oreilly.com/library/view/python-for-data/9781491957653/) by Pandas creator Wes Mckinney for anyone interested in learning how to use Pandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1fded7d-02a7-48c3-99e4-d19d001c8ccf",
   "metadata": {
    "id": "c1fded7d-02a7-48c3-99e4-d19d001c8ccf"
   },
   "outputs": [],
   "source": [
    "data = pd.read_parquet(DATA_DIR / \"mnist.parquet\")\n",
    "features = data.drop(\"label\", axis=1)\n",
    "target = data.loc[:, \"label\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de1d7ed7-50ae-46fb-b7c9-cb3cbd5a6f1b",
   "metadata": {
    "id": "de1d7ed7-50ae-46fb-b7c9-cb3cbd5a6f1b"
   },
   "source": [
    "### Explore the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b53a9c4-550d-4577-bf0f-bace74843784",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9b53a9c4-550d-4577-bf0f-bace74843784",
    "outputId": "f8441f2a-1945-40fb-9409-bf290c79afd2"
   },
   "outputs": [],
   "source": [
    "features.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a672145-6e4a-4a8f-9354-773c665e6139",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 299
    },
    "id": "5a672145-6e4a-4a8f-9354-773c665e6139",
    "outputId": "003969cb-331f-4535-b249-0afb498fdf72"
   },
   "outputs": [],
   "source": [
    "features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed9991ac-7033-475f-aacc-b0ea0d6dded4",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 299
    },
    "id": "ed9991ac-7033-475f-aacc-b0ea0d6dded4",
    "outputId": "2848f8c0-de74-4e52-8643-88dff2b113fd"
   },
   "outputs": [],
   "source": [
    "features.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4983c89-dcbf-4403-8d76-7940d95c9122",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 394
    },
    "id": "d4983c89-dcbf-4403-8d76-7940d95c9122",
    "outputId": "bf57a341-3d7f-4f36-b1dc-552926333a18"
   },
   "outputs": [],
   "source": [
    "features.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9a5d4e9-8c96-4da9-b9b7-33a0edbe018e",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 267
    },
    "id": "f9a5d4e9-8c96-4da9-b9b7-33a0edbe018e",
    "outputId": "2a5ce494-25bd-4490-edb0-5af0d6e93552"
   },
   "outputs": [],
   "source": [
    "_ = (target.value_counts()\n",
    "           .sort_index()\n",
    "           .plot(kind=\"bar\"))\n",
    "_ = plt.xticks(rotation=-45)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4f436f9-7cbb-4cc4-8cbc-ddea21ec9104",
   "metadata": {
    "id": "a4f436f9-7cbb-4cc4-8cbc-ddea21ec9104"
   },
   "source": [
    "### Visualize the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b13b83e1-6264-4fc3-a3ff-cfc9f493be66",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "b13b83e1-6264-4fc3-a3ff-cfc9f493be66",
    "outputId": "d18c8dfb-7d3d-45cf-aef4-125433e1f427"
   },
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(10, 10, sharex=True, sharey=True, figsize=(15, 15))\n",
    "for i in range(10):\n",
    "    for j in range(10):\n",
    "        m, _ = features.shape\n",
    "        k = np.random.randint(m)\n",
    "        img = (features.loc[k, :]\n",
    "                       .to_numpy()\n",
    "                       .reshape((28, 28)))\n",
    "        _ = axes[i, j].imshow(img)\n",
    "        _ = axes[i, j].set_title(target.iloc[k])\n",
    "\n",
    "fig.suptitle(\"Random MNIST images\", x=0.5, y=1.05, fontsize=25)\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e76e54f-947c-4123-89c6-e59eedc3621b",
   "metadata": {
    "id": "1e76e54f-947c-4123-89c6-e59eedc3621b",
    "tags": []
   },
   "source": [
    "# Look at the Big Picture\n",
    "\n",
    "Our goal over these two hands-on workshops will be to build a machine learning modeling pipeline that is capable of classifying images. In part one of this course we will mostly focus on classical machine learning algorithms implemented in Scikit-Learn; in part two we will revist the same problem using deep learning algorithms implemented in PyTorch. By the time you have finished this course you should understand how to build a machine learning application capable of classifying images and be ready to apply what you have learned to a new dataset.\n",
    "\n",
    "This morning we will mostly focus on getting the data and exploring the data to gain new insights. Believe it or not these initial steps are what data scientists and machine learning engineers spend the majority of their time doing! This afternoon we will prepare our data for machine learning, see how to fit a variety of machine learning models to our dataset and shortlist a few candidate models for further analysis. We will then use hyper-parameter tuning to improve the performance of our shortlisted models to arrive at an overall best model. We will finish with a discussion of how to present the results of your model and talk about some of the aspects of deploying a trained model to make predictions.\n",
    "\n",
    "## Framing the problem\n",
    "\n",
    "### What is the business/research objective?\n",
    "\n",
    "Typically building the model is not the overall objective but rather the model itself is one part of a larger process used to answer a business/research question. Knowing the overall objective is important because it will determine your choice of machine learning algorithms to train, your measure(s) of model performance, and how much time you will spend tweaking the hyper-parameters of your model.\n",
    "\n",
    "In our example today, the overall business/research objective is to build a tool for reading electricity meter serial numbers which consist of sequences of sometimes handwritten digits. Part of this tool will be a model that can correctly classify individual handwritten digits. Our image classication model is just one of potentially many other models whose predictions are taken as inputs into another machine learning model that will be used to read off the electricity meter serial numbers. \n",
    "\n",
    "### What is the current solution?\n",
    "\n",
    "Always a good idea to know what the current solution to the problem you are trying to solve. Current solution gives a benchmark for performance. Note that the current \"best\" solution could be very simple or could be very sophisticated. Understanding the current solution helps you think of a good place to start. Example: suppose that the current solution for predicting the price of a house in a given census block is to ignore all the demographic information and predict a simple average of house prices in nearby census blocks. In this case it would probably not make sense to start building a complicated deep learning model to predict housing prices. However, if the current solution was a tuned gradient boosted machine then it probably would not make sense to try a much simpler linear regression model.\n",
    "\n",
    "With all this information, you are now ready to start designing your system. First, you need to frame the problem by answering the following questions.\n",
    "\n",
    "* Is our problem supervised, unsupervised, or reinforcement learning?\n",
    "* Is our problem a classification task, a regression task, or something else? If our problem is a classification task are we trying to classify samples into 2 categories (binary classification) or more than 2 (multi-class classification) categories? If our problem is a regression task, are we trying to predict a single value (univariate regression) or multiple values (multivariate regression) for each sample?\n",
    "* Should you use batch learning or online learning techniques?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a52576a2-4c8e-4707-b021-2e424c4633ee",
   "metadata": {
    "id": "a52576a2-4c8e-4707-b021-2e424c4633ee"
   },
   "source": [
    "### Exercise: Selecting a metric\n",
    "\n",
    "Scikit-Learn has a number of different [possible metrics](https://scikit-learn.org/stable/modules/model_evaluation.html) that you can choose from (or you can create your own custom metric if required). Can you find a few metrics that seems appropriate for our image classification model?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a2212c9-f227-4b8f-ac41-6deb6f714976",
   "metadata": {
    "id": "7a2212c9-f227-4b8f-ac41-6deb6f714976"
   },
   "source": [
    "# Creating a Test Dataset\n",
    "\n",
    "Before we look at the data any further, we need to create a test set, put it aside, and never look at it (until we are ready to test our trainined machine learning model!). Why? We don't want our machine learning model to memorize our dataset (this is called overfitting). Instead we want a model that will generalize well (i.e., make good predictions) for inputs that it didn't see during training. To do this we hold split our dataset into training and testing datasets. The training dataset will be used to train our machine learning model(s) and the testing dataset will be used to make a final evaluation of our machine learning model(s).\n",
    "\n",
    "## If you might refresh data in the future...\n",
    "\n",
    "...then you want to use some particular hashing function to compute the hash of a unique identifier for each observation of data and include the observation in the test set if resulting hash value is less than some fixed percentage of the maximum possible hash value for your algorithm. This way even if you fetch more data, your test set will never include data that was previously included in the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dba37993-2014-4267-9589-fe88d0b21090",
   "metadata": {
    "id": "dba37993-2014-4267-9589-fe88d0b21090"
   },
   "outputs": [],
   "source": [
    "import zlib\n",
    "\n",
    "\n",
    "def in_testing_data(identifier, test_size):\n",
    "    _hash = zlib.crc32(bytes(identifier))\n",
    "    return _hash & 0xffffffff < test_size * 2**32\n",
    "\n",
    "\n",
    "def split_train_test_by_id(data, test_size, id_column):\n",
    "    ids = data[id_column]\n",
    "    in_test_set = ids.apply(lambda identifier: in_testing_data(identifier, test_size))\n",
    "    return data.loc[~in_test_set], data.loc[in_test_set]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6c73954-f3a5-464b-b179-17f7fbe142fb",
   "metadata": {
    "id": "b6c73954-f3a5-464b-b179-17f7fbe142fb"
   },
   "source": [
    "## If this is all the data you will ever have...\n",
    "\n",
    "...then you can just set a seed for the random number generator and then randomly split the data. Scikit-Learn has a [`model_selection`](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html) module that contains tools for splitting datasets into training and testing sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f791e74d-cddd-4383-8a6c-5b80df4a5daf",
   "metadata": {
    "id": "f791e74d-cddd-4383-8a6c-5b80df4a5daf"
   },
   "outputs": [],
   "source": [
    "model_selection.train_test_split?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b35bf11-0fa5-4879-bbda-e976244ec929",
   "metadata": {
    "id": "6b35bf11-0fa5-4879-bbda-e976244ec929"
   },
   "outputs": [],
   "source": [
    "SEED = 42\n",
    "SEED_GENERATOR = np.random.RandomState(SEED)\n",
    "\n",
    "\n",
    "def generate_seed():\n",
    "    return SEED_GENERATOR.randint(np.iinfo(\"uint16\").max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beff5a36-07c7-404f-916b-260c789aff91",
   "metadata": {
    "id": "beff5a36-07c7-404f-916b-260c789aff91"
   },
   "outputs": [],
   "source": [
    "TEST_SIZE = 1e-1\n",
    "\n",
    "# split the dataset into training and testing data\n",
    "_seed = generate_seed()\n",
    "_random_state = np.random.RandomState(_seed)\n",
    "train_features, test_features, train_target, test_target = model_selection.train_test_split(\n",
    "    features,\n",
    "    target,\n",
    "    test_size=TEST_SIZE,\n",
    "    random_state=_random_state\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9ed741c-996c-4df3-8680-49f14cc0dcf0",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "e9ed741c-996c-4df3-8680-49f14cc0dcf0",
    "outputId": "9d66db77-3063-4cfb-8b92-05118d8ddcf8"
   },
   "outputs": [],
   "source": [
    "train_features.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8115616b-7609-4510-8347-b02e497bed84",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 299
    },
    "id": "8115616b-7609-4510-8347-b02e497bed84",
    "outputId": "44beb80e-657b-4a17-fb10-cb521202155f"
   },
   "outputs": [],
   "source": [
    "train_features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3722a295-4c88-4d24-b5cc-b84282f3de57",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3722a295-4c88-4d24-b5cc-b84282f3de57",
    "outputId": "b3bf7ae4-3a92-4403-b393-f7efefeaca6b"
   },
   "outputs": [],
   "source": [
    "train_target.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a75323c-1b45-46b4-80bc-f26b003d50bb",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 394
    },
    "id": "8a75323c-1b45-46b4-80bc-f26b003d50bb",
    "outputId": "198e7d56-3a56-4287-e818-af7ff9998f37"
   },
   "outputs": [],
   "source": [
    "train_features.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "090af9ae-e36c-4c5d-ac2d-25e1ea1c34df",
   "metadata": {
    "id": "090af9ae-e36c-4c5d-ac2d-25e1ea1c34df"
   },
   "source": [
    "Again, if you want to you can write out the train and test sets to disk to avoid having to recreate them later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ede1948-a85a-450f-8c0b-8c18b56ed4d3",
   "metadata": {
    "id": "6ede1948-a85a-450f-8c0b-8c18b56ed4d3"
   },
   "outputs": [],
   "source": [
    "_ = (train_features.join(train_target)\n",
    "                   .to_parquet(DATA_DIR / \"train.parquet\", index=False))\n",
    "\n",
    "_ = (test_features.join(test_target)\n",
    "                   .to_parquet(DATA_DIR / \"test.parquet\", index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4280e020-f990-434c-98b9-361321134432",
   "metadata": {
    "id": "4280e020-f990-434c-98b9-361321134432"
   },
   "source": [
    "# Prepare the data for machine learning algorithms\n",
    "\n",
    "Best practice is to write functions to automate the process of preparing your data for machine learning. Why?\n",
    "\n",
    "* Allows you to reproduce these transformations easily on any dataset.\n",
    "* You will gradually build a library of transformation functions that you can reuse in future projects.\n",
    "* You can use these functions in a live system to transform the new data before feeding it to your algorithms.\n",
    "* This will make it possible for you to easily experiment with various transformations and see which combination of transformations works best.\n",
    "\n",
    "We are working with an benchmark dataset that has already been prepared for analysis (mostly!). You should be aware that academic benchmark datasets are not very representative of the type of datasets that you will encounter in most practical applications. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "626fd519-ffb6-4ae9-be55-53d4a54e53c5",
   "metadata": {
    "id": "626fd519-ffb6-4ae9-be55-53d4a54e53c5"
   },
   "source": [
    "## Feature Scaling\n",
    "\n",
    "Machine learning algorithms typically don’t perform well when the input numerical attributes have very different scales. The simplest approach is to rescale features so that they all reside within the same range (typically between 0 and 1). This approach is implemented in Scikit-Learn by the [`preprocessing.MinMaxScaler`](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.MinMaxScaler.html#sklearn.preprocessing.MinMaxScaler) class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "506f4f98-aa73-46b0-82ce-ebf0d4a0ff81",
   "metadata": {
    "id": "506f4f98-aa73-46b0-82ce-ebf0d4a0ff81"
   },
   "outputs": [],
   "source": [
    "preprocessing.MinMaxScaler?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c00fe28e-a285-4e87-979e-462be36d0815",
   "metadata": {
    "id": "c00fe28e-a285-4e87-979e-462be36d0815"
   },
   "outputs": [],
   "source": [
    "# hyper-parameters\n",
    "_preprocessing_hyperparameters = {\n",
    "    \"feature_range\": (0, 1),\n",
    "    \"copy\": True,\n",
    "    \"clip\": False,\n",
    "}\n",
    "\n",
    "preprocessor = preprocessing.MinMaxScaler(**_preprocessing_hyperparameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33ca8616-d29f-4d47-888c-841f6b823b2e",
   "metadata": {
    "id": "33ca8616-d29f-4d47-888c-841f6b823b2e"
   },
   "outputs": [],
   "source": [
    "preprocessed_train_features = preprocessor.fit_transform(train_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e07170a9-6cb0-4474-8bab-15fec52acc0f",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "e07170a9-6cb0-4474-8bab-15fec52acc0f",
    "outputId": "ba1dfe79-9fd1-4934-b1f4-319b86e05596"
   },
   "outputs": [],
   "source": [
    "preprocessed_train_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df6bf42d-6a72-4b7d-b768-412d5edcb010",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "df6bf42d-6a72-4b7d-b768-412d5edcb010",
    "outputId": "bfdd20f4-32fe-43cc-90ad-d5404a66f798"
   },
   "outputs": [],
   "source": [
    "preprocessed_train_features[:, :5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52de2cc7-960c-43a3-b2de-0a7780b06879",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "52de2cc7-960c-43a3-b2de-0a7780b06879",
    "outputId": "d97803ef-7863-486c-8ca6-ba86621cf4cd"
   },
   "outputs": [],
   "source": [
    "preprocessed_train_features.min(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "034122d4-e0e8-4db9-95b1-0c46b733209d",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "034122d4-e0e8-4db9-95b1-0c46b733209d",
    "outputId": "5a435dd9-efc4-42ec-d7ba-191fadfd6a5f"
   },
   "outputs": [],
   "source": [
    "preprocessed_train_features.mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2306826-abb1-4575-bd53-14f0742131a1",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "d2306826-abb1-4575-bd53-14f0742131a1",
    "outputId": "ea7c8250-f7bf-4cdd-9c57-242b0304ad74"
   },
   "outputs": [],
   "source": [
    "preprocessed_train_features.max(axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bdd7f6c-0c01-46aa-b2c3-8dce85005f76",
   "metadata": {
    "id": "4bdd7f6c-0c01-46aa-b2c3-8dce85005f76"
   },
   "source": [
    "The `preprocessing.MinMaxScaler` and the `preprocessing.StandardScaler` classes are the first Scikit-Learn `Transformer` classes that we have encountered. As such now is a good to to discuss the Scikit-Learn application programming interface (API). The [Scikit-Learn API](https://scikit-learn.org/stable/modules/classes.html) is one of the best designed API's around and has heavily influenced API design choices of other libraries in the Python Data Science and Machine Learning ecosystem, in particular [Dask](https://dask.org/) and [NVIDIA RAPIDS](https://rapids.ai/). Familiarly with the Scikit-Learn API will make it easier for you to get started with these libraries.\n",
    "\n",
    "The Scikit-Learn API is built around the following key concepts.\n",
    "\n",
    "* Estimators: Any object that can estimate some parameters based on a dataset is called an estimator (e.g., an `preprocessing.MinMaxScaler` is an estimator). The estimation itself is performed by the `fit` method, and it takes only a dataset as a parameter (or two for supervised learning algorithms; the second dataset contains the labels). Any other parameter needed to guide the estimation process is considered a hyperparameter (such as the `feature_range` parameter in `preprocessing.MinMaxScaler`), and it must be set as an instance variable (generally via a constructor parameter).\n",
    "\n",
    "* Transformers: Some estimators (such as an `preprocessing.MinMaxScaler`) can also transform a dataset; these are called transformers. Once again, the API is simple: the transformation is performed by the transform method with the dataset to transform as a parameter. It returns the transformed dataset. This transformation generally relies on the learned parameters. All transformers also have a convenience method called `fit_transform` that is equivalent to calling `fit` and then `transform` (but sometimes `fit_transform` is optimized and runs much faster).\n",
    "\n",
    "* Predictors: Finally, some estimators, given a dataset, are capable of making predictions; they are called predictors. A predictor has a `predict` method that takes a dataset of new instances and returns a dataset of corresponding predictions. It also has a score method that measures the quality of the predictions, given a test set (and the corresponding labels, in the case of supervised learning algorithms).\n",
    "\n",
    "All of an estimator’s hyperparameters are accessible directly via public instance variables (e.g., `preprocessor.feature_range`), and all the estimator’s learned parameters are accessible via public instance variables with an underscore suffix (e.g., `preprocessor.scale_`). Finally, Scikit-Learn provides reasonable default values for most parameters which makes it easy to quickly create a baseline working system."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6afd0ab6-3d65-466c-b2d6-8926601d4f3d",
   "metadata": {
    "id": "6afd0ab6-3d65-466c-b2d6-8926601d4f3d"
   },
   "source": [
    "### Exercise: MinMaxScaler vs StandardScaler\n",
    "\n",
    "An alternative approach is to rescale features so that they all have zero mean and unit standard deviation. This approach, which is also called standardization, is particularly useful when attributes/features have outliers and when downstream machine learning algorithms assume that attributes/features have a Gaussian or Normal distribution. \n",
    "\n",
    "Create an instance of the [`preprocessing.StandardScaler`](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html) class and use it to rescale the training dataset. Compare the two different rescaled versions of the dataset. Which of the two methods do you prefer?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a58ce5ba-4568-4f39-a620-93b7fe402396",
   "metadata": {
    "id": "a58ce5ba-4568-4f39-a620-93b7fe402396"
   },
   "outputs": [],
   "source": [
    "_hyperparameters = {\n",
    "    \"copy\": True,\n",
    "    \"with_mean\": True,\n",
    "    \"with_std\": True\n",
    "}\n",
    "preprocessor = preprocessing.StandardScaler(**_hyperparameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "xZdeA_2vmS0z",
   "metadata": {
    "id": "xZdeA_2vmS0z"
   },
   "outputs": [],
   "source": [
    "preprocessed_train_features = preprocessor.fit_transform(train_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "_TjJqHgtmS36",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_TjJqHgtmS36",
    "outputId": "9db6ef16-3ebc-46b6-db40-18a6151d72d9"
   },
   "outputs": [],
   "source": [
    "preprocessed_train_features.mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Ld2pk-ahmTF9",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Ld2pk-ahmTF9",
    "outputId": "692fb2e6-b699-45c3-e1ad-a70f62c61925"
   },
   "outputs": [],
   "source": [
    "preprocessed_train_features.std(axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d04a639-ba99-47b5-936a-7c6a555c6f08",
   "metadata": {
    "id": "3d04a639-ba99-47b5-936a-7c6a555c6f08"
   },
   "source": [
    "As with all the transformations, it is important to fit the scalers to the training data only, not to the full dataset (including the test set). Only then can you use them to transform the training set and the test set (and new data)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b258fe6-475d-46f1-8349-9be26ae9f70e",
   "metadata": {
    "id": "6b258fe6-475d-46f1-8349-9be26ae9f70e"
   },
   "source": [
    "## Transformation pipelines\n",
    "\n",
    "Creating preprocessing pipelines typically involves quite a lot of steps and each of the steps needs to be executed in the correct order. Fortunately Scikit-Learn allows you to combine estimators together to create [pipelines](https://scikit-learn.org/stable/modules/compose.html#combining-estimators). We can encapsulate all of the preprocessing logic into instances of the [`Pipeline`](https://scikit-learn.org/stable/modules/generated/sklearn.pipeline.Pipeline.html#sklearn.pipeline.Pipeline) class.\n",
    "\n",
    "The `Pipeline` constructor takes a list of name/estimator pairs defining a sequence of steps. All but the last estimator must be transformers (i.e., they must have a `fit_transform` method). The names can be anything you like (as long as they are unique). Later we will see how to access the parameters of pipelines using these names when we discuss hyperparameter tuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "462144af-2e79-4ec8-b0bd-d9c9933ac32f",
   "metadata": {
    "id": "462144af-2e79-4ec8-b0bd-d9c9933ac32f"
   },
   "outputs": [],
   "source": [
    "_seed = generate_seed()\n",
    "\n",
    "# hyper-parameters\n",
    "_min_max_scaler_hyperparameters = {\n",
    "    \"feature_range\": (0, 1)\n",
    "}\n",
    "\n",
    "# default Pipeline constructor\n",
    "preparation_pipeline = pipeline.Pipeline(\n",
    "    [\n",
    "        (\"minmaxscaler\", preprocessing.MinMaxScaler(**_min_max_scaler_hyperparameters)),\n",
    "    ],\n",
    "    verbose=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0034f083-3b70-4113-a971-883ee1f5d1ed",
   "metadata": {
    "id": "0034f083-3b70-4113-a971-883ee1f5d1ed"
   },
   "outputs": [],
   "source": [
    "_seed = generate_seed()\n",
    "\n",
    "# hyper-parameters\n",
    "_min_max_scaler_hyperparameters = {\n",
    "    \"feature_range\": (0, 1)\n",
    "}\n",
    "\n",
    "# alternative constructor that is equivalent to the above!\n",
    "preparation_pipeline = pipeline.make_pipeline(\n",
    "    preprocessing.MinMaxScaler(**_min_max_scaler_hyperparameters),\n",
    "    verbose=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c64d85c-11ba-4a3f-86db-0e1eb4d9f8a3",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7c64d85c-11ba-4a3f-86db-0e1eb4d9f8a3",
    "outputId": "c97b6a68-537b-4471-ee7f-73cf026a6b1a"
   },
   "outputs": [],
   "source": [
    "prepared_train_features = preparation_pipeline.fit_transform(train_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3c91d3d-f2ea-48a1-b7fa-204bc9f1ddab",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "f3c91d3d-f2ea-48a1-b7fa-204bc9f1ddab",
    "outputId": "07895363-c81e-4ad9-a5fa-da6ed0faf372"
   },
   "outputs": [],
   "source": [
    "prepared_train_features.min(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc6d4c3f-a34f-4f94-8dc6-e833f2902b47",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bc6d4c3f-a34f-4f94-8dc6-e833f2902b47",
    "outputId": "15e33316-2f40-4cb4-af90-36e54bcb4ed1"
   },
   "outputs": [],
   "source": [
    "prepared_train_features.mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c20f7251-59d6-4d93-b0fe-97a5f7e1c91f",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "c20f7251-59d6-4d93-b0fe-97a5f7e1c91f",
    "outputId": "bf2dd41e-32a3-405f-ae9b-1610e500a283"
   },
   "outputs": [],
   "source": [
    "prepared_train_features.max(axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01b292be-f7b9-4958-a6d0-c957ebcc50a5",
   "metadata": {
    "id": "01b292be-f7b9-4958-a6d0-c957ebcc50a5"
   },
   "source": [
    "# Select and train a model\n",
    "\n",
    "At last! You framed the problem, you got the data and explored it, you sampled a training set and a test set, and you wrote transformation pipelines to clean up and prepare your data for machine learning algorithms automatically. You are now ready to select and train a Machine Learning model. You might have been wondering if we were every going to make it to this point! Fact is, most of your time developing machine learning solutions to real-world problems will not be spent training machine learning models: most of your time will be spent preparing the data for machine learning algorithms and most of the computer time will be spent training the machine learning models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e627d70a-418f-49ed-8449-5ba412a77d2c",
   "metadata": {
    "id": "e627d70a-418f-49ed-8449-5ba412a77d2c"
   },
   "source": [
    "## Training and evaluating on the training dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ce4c846-8197-49fd-9391-493cbac70208",
   "metadata": {
    "id": "0ce4c846-8197-49fd-9391-493cbac70208"
   },
   "source": [
    "### Linear models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fb069c7-a23b-4d00-9529-25ec8b73ea26",
   "metadata": {
    "id": "8fb069c7-a23b-4d00-9529-25ec8b73ea26"
   },
   "outputs": [],
   "source": [
    "_seed = generate_seed()\n",
    "\n",
    "# hyper-parameters\n",
    "_min_max_scaler_hyperparameters = {\n",
    "    \"feature_range\": (0, 1)\n",
    "}\n",
    "\n",
    "_classifier_hyperparameters = {\n",
    "    \"fit_intercept\": True,\n",
    "    \"loss\": \"log_loss\",\n",
    "    \"penalty\": None,\n",
    "    \"random_state\": np.random.RandomState(_seed),\n",
    "    \"n_jobs\": -1,\n",
    "}\n",
    "\n",
    "ml_pipeline = pipeline.make_pipeline(\n",
    "    preprocessing.MinMaxScaler(**_min_max_scaler_hyperparameters),\n",
    "    linear_model.SGDClassifier(**_classifier_hyperparameters),\n",
    "    verbose=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f03c868d-0835-427d-a668-63809b70e65d",
   "metadata": {
    "id": "f03c868d-0835-427d-a668-63809b70e65d"
   },
   "outputs": [],
   "source": [
    "_ = ml_pipeline.fit(train_features, train_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bc88278-3197-41f0-9600-527206c34c63",
   "metadata": {
    "id": "5bc88278-3197-41f0-9600-527206c34c63"
   },
   "outputs": [],
   "source": [
    "train_predictions = ml_pipeline.predict(train_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e324613b-9ddc-4c2b-b0e7-b0ff34cc3576",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "e324613b-9ddc-4c2b-b0e7-b0ff34cc3576",
    "outputId": "d3f3604b-9056-4af7-bdd6-ab9930d31cab"
   },
   "outputs": [],
   "source": [
    "train_predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e99063b9-cb93-45cc-b1c7-07abf3cbf3f3",
   "metadata": {
    "id": "e99063b9-cb93-45cc-b1c7-07abf3cbf3f3"
   },
   "source": [
    "### Mini-batch gradient descent\n",
    "\n",
    "Since we talked about the difference between stochastic, batch, and mini-batch gradient descent in the lectures I wanted you to see how to implement mini-batch gradient descent in Scikit-Learn. You will see much more of this idea in the deep learning hands on session so we will not spend too much time on it now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "791d5512-923e-4c01-ad58-e28aca768f44",
   "metadata": {
    "id": "791d5512-923e-4c01-ad58-e28aca768f44",
    "tags": []
   },
   "outputs": [],
   "source": [
    "_seed = generate_seed()\n",
    "_random_state = np.random.RandomState(_seed)\n",
    "\n",
    "n_epochs = 2\n",
    "batch_size = 128\n",
    "X = train_features\n",
    "y = train_target\n",
    "m, _ = X.shape\n",
    "\n",
    "# define your estimator\n",
    "_classifier_hyperparameters = {\n",
    "    \"alpha\": 1e-4,\n",
    "    \"fit_intercept\": False,\n",
    "    \"l1_ratio\": 0.15,\n",
    "    \"learning_rate\": \"optimal\",\n",
    "    \"loss\": \"log_loss\",\n",
    "    \"n_jobs\": -1,\n",
    "    \"penalty\": None,\n",
    "    \"random_state\": _random_state,\n",
    "    \"warm_start\": True,\n",
    "}\n",
    "estimator = linear_model.SGDClassifier(**_classifier_hyperparameters)\n",
    "\n",
    "# nested for loops implement the training\n",
    "for _ in range(n_epochs):\n",
    "\n",
    "    # shuffle the dataset before every training epoch\n",
    "    shuffled_indices = _random_state.permutation(m)\n",
    "    _X, _y = X.iloc[shuffled_indices], y.iloc[shuffled_indices]\n",
    "\n",
    "    for batch_ixs in utils.gen_batches(m, batch_size):\n",
    "        _ = estimator.partial_fit(_X[batch_ixs], _y[batch_ixs], classes=y.unique())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e83cb8be-2603-45a0-9085-f3dbdd3154ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_predictions = estimator.predict(train_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "699884cb-30c4-4135-9e66-35a0d1eea255",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ada04802-5ae9-4285-bdd5-d8b6ae40057e",
   "metadata": {
    "id": "ada04802-5ae9-4285-bdd5-d8b6ae40057e"
   },
   "source": [
    "Congrats! You have fit your first machine learning model using Scikit-Learn and made some predictions. Now let's see how good those predictions really are."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38833161-7ebe-4b97-8bef-91159c69e939",
   "metadata": {
    "id": "38833161-7ebe-4b97-8bef-91159c69e939"
   },
   "source": [
    "### Evaluation metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ef1a3be-ada7-4fed-9813-b1158d7aaeab",
   "metadata": {
    "id": "2ef1a3be-ada7-4fed-9813-b1158d7aaeab"
   },
   "source": [
    "#### Confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2caaf7d3-cf20-4008-878e-f57a261db011",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2caaf7d3-cf20-4008-878e-f57a261db011",
    "outputId": "748a29de-b5a3-4ccf-cdf9-79b405f47918"
   },
   "outputs": [],
   "source": [
    "confusion_matrix = metrics.confusion_matrix(\n",
    "    train_target,\n",
    "    train_predictions,\n",
    ")\n",
    "confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89a0bf8f-ca7d-43fd-804f-8819fe69c005",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 611
    },
    "id": "89a0bf8f-ca7d-43fd-804f-8819fe69c005",
    "outputId": "cf9edc81-126d-4542-a932-81a0f0734ae1"
   },
   "outputs": [],
   "source": [
    "# visualize the normalized confusion matrix\n",
    "fig, ax = plt.subplots(1, 1, figsize=(10, 10))\n",
    "_normalized_confusion_matrix = confusion_matrix / confusion_matrix.sum(axis=1, keepdims=True)\n",
    "np.fill_diagonal(_normalized_confusion_matrix, 0)\n",
    "_ = ax.matshow(_normalized_confusion_matrix)\n",
    "_ = ax.set_xlabel(\"Predicted Class\", fontsize=15)\n",
    "_ = ax.set_ylabel(\"Actual Class\", fontsize=15)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dc0e2e7-4fb3-4cd8-950a-da82c4be4095",
   "metadata": {
    "id": "5dc0e2e7-4fb3-4cd8-950a-da82c4be4095"
   },
   "source": [
    "#### Precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2280294c-d524-49fc-bb53-9083662a7fad",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2280294c-d524-49fc-bb53-9083662a7fad",
    "outputId": "ac81c392-8af2-4f52-fedb-74a7134b4971"
   },
   "outputs": [],
   "source": [
    "metrics.precision_score(\n",
    "    train_target,\n",
    "    train_predictions,\n",
    "    average=\"macro\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfbf5770-4c74-4212-b6de-de5637afcba3",
   "metadata": {
    "id": "cfbf5770-4c74-4212-b6de-de5637afcba3"
   },
   "source": [
    "#### Recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccc68c19-f248-4e08-8ab2-565d9aeb3ac5",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ccc68c19-f248-4e08-8ab2-565d9aeb3ac5",
    "outputId": "09b13463-1266-4a4d-b4ff-a91074fb77db"
   },
   "outputs": [],
   "source": [
    "metrics.recall_score(\n",
    "    train_target,\n",
    "    train_predictions,\n",
    "    average=\"macro\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0065ef0-4bf0-403a-a6a4-219db9a44589",
   "metadata": {
    "id": "c0065ef0-4bf0-403a-a6a4-219db9a44589"
   },
   "source": [
    "#### $F_1$ Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1f8aafe-a87c-4e90-8b2f-4ecfbe2d31e8",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "d1f8aafe-a87c-4e90-8b2f-4ecfbe2d31e8",
    "outputId": "69fbbdf7-f62a-4aa3-beef-8316039c36de"
   },
   "outputs": [],
   "source": [
    "metrics.f1_score(\n",
    "    train_target,\n",
    "    train_predictions,\n",
    "    average=\"macro\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f89d8a5-caf1-47fc-90af-9896a3767780",
   "metadata": {
    "id": "1f89d8a5-caf1-47fc-90af-9896a3767780"
   },
   "source": [
    "#### Receiver Operating Characteristic (ROC) Area Under the Curve (AUC) Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87fcb8e6-243f-4d1e-be2f-90f03e3a1311",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "87fcb8e6-243f-4d1e-be2f-90f03e3a1311",
    "outputId": "d053de55-4203-4850-87a3-1f5a1570fabd"
   },
   "outputs": [],
   "source": [
    "_scores = ml_pipeline.predict_proba(train_features)\n",
    "metrics.roc_auc_score(\n",
    "    train_target,\n",
    "    _scores,\n",
    "    average=\"macro\",\n",
    "    multi_class=\"ovo\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b434767-0619-42a2-8577-a81c3616d0cd",
   "metadata": {
    "id": "3b434767-0619-42a2-8577-a81c3616d0cd"
   },
   "source": [
    "#### Classification report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afe04cef-c14c-4735-a7fa-c2131bce5344",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "afe04cef-c14c-4735-a7fa-c2131bce5344",
    "outputId": "cd34baef-a297-45f6-f92e-08eab08d96c2"
   },
   "outputs": [],
   "source": [
    "_report = metrics.classification_report(\n",
    "    train_target,\n",
    "    train_predictions,\n",
    ")\n",
    "print(_report)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4e6030a-4a88-4dd6-82a3-66e606686331",
   "metadata": {},
   "source": [
    "### Estimating Generalization Error using Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f0e23a7-4f86-482b-ae74-f6e92e928837",
   "metadata": {},
   "outputs": [],
   "source": [
    "CV_FOLDS = 3\n",
    "\n",
    "estimator_scores = model_selection.cross_val_score(\n",
    "    ml_pipeline,\n",
    "    X=train_features,\n",
    "    y=train_target,\n",
    "    cv=CV_FOLDS,\n",
    "    scoring=\"accuracy\",\n",
    "    n_jobs=-1,\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78db7961-77a9-480b-9e28-7e05de150d9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator_scores.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b83394a-50f1-49e1-9526-8098090b7c9a",
   "metadata": {
    "id": "2b83394a-50f1-49e1-9526-8098090b7c9a"
   },
   "outputs": [],
   "source": [
    "# make predictions\n",
    "_train_predictions = model_selection.cross_val_predict(\n",
    "    ml_pipeline,\n",
    "    X=train_features,\n",
    "    y=train_target,\n",
    "    cv=CV_FOLDS,\n",
    "    n_jobs=-1,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# report the accuracy on the training data\n",
    "_report = metrics.classification_report(\n",
    "    train_target,\n",
    "    _train_predictions,\n",
    ")\n",
    "print(_report)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dadeb7f8-ee55-4fe6-91f1-4beaf306affc",
   "metadata": {
    "id": "dadeb7f8-ee55-4fe6-91f1-4beaf306affc"
   },
   "source": [
    "### Discussion\n",
    "\n",
    "What is going on here? Are we underfitting? Are we overfitting? If you think that we are underfitting, then what could we do to try and get the model to overfit? If we are overfitting, what could we do to get the model to underfit?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c979240-7d8b-4426-80ab-4d6842bdf766",
   "metadata": {
    "id": "7c979240-7d8b-4426-80ab-4d6842bdf766"
   },
   "source": [
    "### Exercise: Regularizing Linear Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8441712c-2962-4720-a355-e7d4337e71a3",
   "metadata": {
    "id": "8441712c-2962-4720-a355-e7d4337e71a3"
   },
   "outputs": [],
   "source": [
    "linear_model.SGDClassifier?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b66d6f3e-4613-4d85-bac8-0e6bb929d398",
   "metadata": {
    "id": "b66d6f3e-4613-4d85-bac8-0e6bb929d398"
   },
   "outputs": [],
   "source": [
    "_seed = generate_seed()\n",
    "_classifier_hyperparameters = {\n",
    "    \"alpha\": 1e-4, # try changing this!\n",
    "    \"fit_intercept\": True,\n",
    "    \"l1_ratio\": 0.15, # only used for penalty=elastic_net\n",
    "    \"loss\": \"log_loss\",\n",
    "    \"n_jobs\": -1,\n",
    "    \"penalty\": None, # try changing this!\n",
    "    \"random_state\": np.random.RandomState(_seed),\n",
    "}\n",
    "\n",
    "ml_pipeline = pipeline.make_pipeline(\n",
    "    preprocessing.MinMaxScaler(),\n",
    "    linear_model.SGDClassifier(**_classifier_hyperparameters),\n",
    "    verbose=True,\n",
    ")\n",
    "\n",
    "# make predictions\n",
    "_train_predictions = model_selection.cross_val_predict(\n",
    "    ml_pipeline,\n",
    "    X=train_features,\n",
    "    y=train_target,\n",
    "    cv=CV_FOLDS,\n",
    "    n_jobs=-1,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# report the accuracy on the training data\n",
    "_report = metrics.classification_report(\n",
    "    train_target,\n",
    "    _train_predictions,\n",
    ")\n",
    "print(_report)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efe7255e-4f60-469c-b541-f6935d9cb6e1",
   "metadata": {
    "id": "efe7255e-4f60-469c-b541-f6935d9cb6e1"
   },
   "source": [
    "# Evaluate your models on the test dataset\n",
    "\n",
    "After tweaking your models for a while, you eventually have a system that performs sufficiently well. Now is the time to evaluate the final model on the test set. First, we need to re-fit the pipeline using the full training data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce4dfe88-ce70-452f-9256-dc39a3211375",
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = ml_pipeline.fit(train_features, train_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a73ca70-1d2b-4053-b500-5d0be0c19f62",
   "metadata": {
    "id": "8a73ca70-1d2b-4053-b500-5d0be0c19f62"
   },
   "outputs": [],
   "source": [
    "# make predictions\n",
    "test_predictions = ml_pipeline.predict(test_features)\n",
    "\n",
    "# generate a classification report\n",
    "_report = metrics.classification_report(\n",
    "    test_target,\n",
    "    test_predictions,\n",
    ")\n",
    "print(_report)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e549fff1-33ab-4e1d-9f1f-605207a88c67",
   "metadata": {},
   "source": [
    "Finally, we can save our trained model to disk for later use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed2cedef-b497-4eda-9bbd-ab04263e2087",
   "metadata": {
    "id": "ed2cedef-b497-4eda-9bbd-ab04263e2087"
   },
   "outputs": [],
   "source": [
    "_ = joblib.dump(ml_pipeline, RESULTS_DIR / \"linear-model.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eec43a20-61da-4edb-b2e8-673adc6b7d3a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
